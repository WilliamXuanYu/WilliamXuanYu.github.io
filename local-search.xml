<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>应用spacy的中文分词尝试</title>
    <link href="/2023/01/10/%E5%BA%94%E7%94%A8spacy%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%B0%9D%E8%AF%95/"/>
    <url>/2023/01/10/%E5%BA%94%E7%94%A8spacy%E7%9A%84%E4%B8%AD%E6%96%87%E5%88%86%E8%AF%8D%E5%B0%9D%E8%AF%95/</url>
    
    <content type="html"><![CDATA[<h1 id="一、安装-SpaCy"><a href="#一、安装-SpaCy" class="headerlink" title="一、安装 SpaCy"></a>一、安装 <a href="https://so.csdn.net/so/search?q=SpaCy&amp;spm=1001.2101.3001.7020">SpaCy</a></h1><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs cmake">pip <span class="hljs-keyword">install</span> spacy<br></code></pre></td></tr></table></figure><h1 id="二、英文分词"><a href="#二、英文分词" class="headerlink" title="二、英文分词"></a>二、英文分词</h1><ol><li>安装英文库</li></ol><hr><figure class="highlight vim"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vim"><span class="hljs-keyword">python</span> -<span class="hljs-keyword">m</span> spacy download <span class="hljs-keyword">en</span><br></code></pre></td></tr></table></figure><ol><li>分词</li></ol><hr><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> spacy<br><br>spacy_en = spacy.<span class="hljs-keyword">load</span>(&quot;en_core_web_sm&quot;)<br><br>def tokenize_en(<span class="hljs-type">text</span>):<br>    <span class="hljs-keyword">return</span> [tok.text <span class="hljs-keyword">for</span> tok <span class="hljs-keyword">in</span> spacy_en.tokenizer(<span class="hljs-type">text</span>)]<br><br>print(tokenize_en(&quot;Hello, my name is tom.&quot;))<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;Hello</span>&#x27;, &#x27;,&#x27;, <span class="hljs-symbol">&#x27;my</span>&#x27;, <span class="hljs-symbol">&#x27;name</span>&#x27;, <span class="hljs-symbol">&#x27;is</span>&#x27;, <span class="hljs-symbol">&#x27;tom</span>&#x27;, <span class="hljs-symbol">&#x27;.</span>&#x27;]<br></code></pre></td></tr></table></figure><h1 id="三、中文分词"><a href="#三、中文分词" class="headerlink" title="三、中文分词"></a>三、中文分词</h1><ol><li>安装中文库</li></ol><hr><figure class="highlight ebnf"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs ebnf"><span class="hljs-attribute">python -m spacy download zh_core_web_sm</span><br></code></pre></td></tr></table></figure><ol><li>分词</li></ol><hr><figure class="highlight pgsql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs pgsql"><span class="hljs-keyword">import</span> spacy<br><br>spacy_zh = spacy.<span class="hljs-keyword">load</span>(&quot;zh_core_web_sm&quot;)<br><br><br>def tokenize_zh(<span class="hljs-type">text</span>):<br>    <span class="hljs-keyword">return</span> [tok.text <span class="hljs-keyword">for</span> tok <span class="hljs-keyword">in</span> spacy_zh.tokenizer(<span class="hljs-type">text</span>)]<br><br><br>print(tokenize_zh(&quot;你好，我的名字叫汤姆&quot;))<br></code></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight scheme"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs scheme">[<span class="hljs-symbol">&#x27;你好</span>&#x27;, <span class="hljs-symbol">&#x27;，</span>&#x27;, <span class="hljs-symbol">&#x27;我</span>&#x27;, <span class="hljs-symbol">&#x27;的</span>&#x27;, <span class="hljs-symbol">&#x27;名字</span>&#x27;, <span class="hljs-symbol">&#x27;叫</span>&#x27;, <span class="hljs-symbol">&#x27;汤姆</span>&#x27;]<br></code></pre></td></tr></table></figure><p>官网上提供有三个中文模型：<br>zh_core_web_sm<br>zh_core_web_md<br>zh_core_web_lg</p><p>安装方式：</p><figure class="highlight mel"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs mel"><span class="hljs-keyword">python</span> -m spacy download zh_core_web_sm<br><span class="hljs-keyword">python</span> -m spacy download zh_core_web_md<br><span class="hljs-keyword">python</span> -m spacy download zh_core_web_lg<br></code></pre></td></tr></table></figure><h1 id="四、解析"><a href="#四、解析" class="headerlink" title="四、解析"></a>四、解析</h1><p>运行下列程序：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs python">text = <span class="hljs-string">&quot;The rain in Spain falls mainly on the plain.&quot;</span><br>doc = nlp(text)<br><br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:    <br>    <span class="hljs-built_in">print</span>(token.text, token.lemma_, token.pos_, token.is_stop)<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python">The the DET Truerain <br>rain NOUN Falsein <br><span class="hljs-keyword">in</span> ADP TrueSpain <br>Spain PROPN <span class="hljs-literal">False</span><br>falls fall VERB Falsemainly <br>mainly ADV <span class="hljs-literal">False</span><br>on on ADP <span class="hljs-literal">True</span><br>the the DET Trueplain <br>plain NOUN <span class="hljs-literal">False</span><br>. . PUNCT <span class="hljs-literal">False</span><br></code></pre></td></tr></table></figure><p>解析：</p><p><img src="https://image.jiqizhixin.com/uploads/editor/8743cf1b-ff7f-4ef1-bb13-55296039da5e/640.png" alt="img"></p><ul><li>文本</li><li>词根</li><li>位置</li><li>词性（按上述表格顺序）<ul><li>限定词</li><li>名词</li><li>附加</li><li>专有名词</li><li>动词</li><li>副词</li><li>附加</li><li>限定词</li><li>名词</li><li>标点</li></ul></li><li>停用词</li></ul><p><img src="https://picture-for-mark.oss-cn-hangzhou.aliyuncs.com/img/202301101934684.png" alt="img"></p><h1 id="五、实际处理"><a href="#五、实际处理" class="headerlink" title="五、实际处理"></a>五、实际处理</h1><h2 id="英文"><a href="#英文" class="headerlink" title="英文"></a>英文</h2><p>可以利用string 去除标点，set 去重</p><p>该nlp变量现在是您通向所有spaCy的入口，并装载了en_core_web_sm英文模型</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> spacy<br>nlp = spacy.load(<span class="hljs-string">&#x27;en_core_web_sm&#x27;</span>) <span class="hljs-comment">#加载spacy</span><br>txt = <span class="hljs-string">&quot;A magnetic monopole is a hypothetical elementary particle.&quot;</span><br>doc = nlp(txt) <span class="hljs-comment"># 这里的doc是spaCy中的一种数据结构</span><br>list1=[]<br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:<br>    token=token.lemma_   <span class="hljs-comment">#词干化</span><br>    <span class="hljs-keyword">if</span> token <span class="hljs-keyword">not</span> <span class="hljs-keyword">in</span> string.punctuation: <span class="hljs-comment">#去除所有标点</span><br>        list1.append(token)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">set</span>(list1))<br></code></pre></td></tr></table></figure><p><img src="https://picture-for-mark.oss-cn-hangzhou.aliyuncs.com/img/202301101917153.png" alt="image-20230110191710080"></p><h2 id="中文"><a href="#中文" class="headerlink" title="中文"></a>中文</h2><p>中文下不必进行词根处理（强行使用token=token.lemma_操作会报错）</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> spacy<br><br>nlp = spacy.load(<span class="hljs-string">&#x27;zh_core_web_sm&#x27;</span>) <span class="hljs-comment">#加载spacy</span><br>txt = <span class="hljs-string">&quot;你好，我的名字叫汤姆&quot;</span><br>doc = nlp(txt)<br><br>list1=[]<br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:<br>    <span class="hljs-keyword">if</span> token.is_stop == <span class="hljs-literal">False</span>: <span class="hljs-comment">#去除停用词</span><br>        list1.append(token)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">set</span>(list1)) <span class="hljs-comment">#去重</span><br></code></pre></td></tr></table></figure><p><img src="https://picture-for-mark.oss-cn-hangzhou.aliyuncs.com/img/202301101938768.png" alt="image-20230110193842741"></p><h2 id="实际数据"><a href="#实际数据" class="headerlink" title="实际数据"></a>实际数据</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> spacy<br><br>nlp = spacy.load(<span class="hljs-string">&#x27;zh_core_web_sm&#x27;</span>) <span class="hljs-comment">#加载spacy</span><br>txt = <span class="hljs-string">&quot;一直认为法国菜吃的是精致，而意大利菜吃的就是气氛。喜欢分享，是意大利餐饮文化的精髓，所以用餐时那氛围就感觉比较轻松，最适合朋友和家庭聚会。&quot;</span> \<br>      <span class="hljs-string">&quot;这天，苏苏与朋友们来到澳门银河酒店的庭园意大利餐厅聚一聚。&quot;</span> \<br>      <span class="hljs-string">&quot;餐厅在酒店2楼，在东翼的贵宾大堂入口旁就有升降机直接到达，踏出升降机，走进一道非常漂亮的走廊。&quot;</span> \<br>      <span class="hljs-string">&quot;在这里打卡很不错。&quot;</span> \<br>      <span class="hljs-string">&quot;走到尽头就看见了漂亮的餐厅入口。&quot;</span> \<br>      <span class="hljs-string">&quot;装潢是典雅华丽的意大利风格，空间感很充足。&quot;</span> \<br>      <span class="hljs-string">&quot;厨房是开放式的，让客人可以欣赏大厨们的厨艺。&quot;</span> \<br>      <span class="hljs-string">&quot;苏苏已经看过很多次了，所以跟好友在餐桌上小酌一杯。餐厅有个藏酒库，有不少美酒在内，有兴趣可以问服务员拿酒单的。&quot;</span> \<br>      <span class="hljs-string">&quot;蕃茄香草面包&quot;</span> \<br>      <span class="hljs-string">&quot;餐厅自家制的面包，口感松软，香气四溢，用橄榄油和意大利黑醋同吃，滋味满腔。我们还在等两个朋友，一边小酌一边吃面包，不知不觉，我俩将整盆吃掉了。&quot;</span> \<br>      <span class="hljs-string">&quot;朋友们来了，可以起菜啦。&quot;</span> \<br>      <span class="hljs-string">&quot;火箭菜沙律&quot;</span> \<br>      <span class="hljs-string">&quot;苏苏超爱吃火箭菜(也称为芝麻菜)沙律，看着服务员在我们面前制作沙律，感觉特别新鲜，还有即切的芝士，看着时口水在心中一直流.....尝起来口感脆脆的火箭菜带点独有香气，还有橄榄油和柠檬汁等调味料搭配，十分开胃，可以为之后的美食作准备。&quot;</span> \<br>      <span class="hljs-string">&quot;黑毛猪火腿配意大利甜蜜&quot;</span> \<br>      <span class="hljs-string">&quot;毛猪火腿充满甘香、油香和果香，味道浓郁，是苏苏很爱的其中一种食材，这道配上意大利超甜蜜瓜，吃在口中，那种咸甜交错的滋味，幸福感满满的。&quot;</span> \<br>      <span class="hljs-string">&quot;芝士肉肠开心果薄饼&quot;</span> \<br>      <span class="hljs-string">&quot;在意大利餐厅用餐，绝对不能错过经典的披萨。&quot;</span> \<br>      <span class="hljs-string">&quot;除了披萨上的芝士和肉肠很好吃外，还有苏苏未在披萨里吃过的开心果碎，配搭真的很新鲜。披萨皮的部份更是让苏苏回味，它是薄皮的但有嚼劲Q感的手工皮披萨，面团很香，边是脆脆的，苏苏忍不住口，一口气吃了两件。&quot;</span> \<br>      <span class="hljs-string">&quot;章鱼土豆&quot;</span> \<br>      <span class="hljs-string">&quot;好吃的章鱼是来自意大利的，触手上的吸盘有两排，只有一排吸盘的，口感没有意大利沿岸生长的章鱼好吃。而这份章鱼就是有两排吸盘的，而且烹调得宜，口感软糯，搭配土豆的香味和伴吃的酱汁，好吃。&quot;</span> \<br>      <span class="hljs-string">&quot;战斧牛扒&quot;</span> \<br>      <span class="hljs-string">&quot;位于牛的上肋部连骨的肉扒，长长的骨头似印弟安战斧，故此得名。&quot;</span> \<br>      <span class="hljs-string">&quot;苏苏是牛魔王，很爱吃牛，特别是战斧牛扒，因为牛骨中的骨髓和脂肪加强了牛肉的味道，骨肉相连间的骨胶原能保持肉质湿润软滑，加上大型牛骨帮助固定牛扒形状，肉汁不会在牛扒熟成及烹调时因缩水而流失，味道更浓更集中。&quot;</span> \<br>      <span class="hljs-string">&quot;这一份大厨在烹调时火喉控制得宜，肉质口感嫩滑，牛肉味浓郁，十分好吃。&quot;</span> \<br>      <span class="hljs-string">&quot;拉米苏Tiramisu&quot;</span> \<br>      <span class="hljs-string">&quot;甜品一定要推介现场做的提拉米苏，苦与甜的平衡度恰到好处，还有可以欣赏专业人员在你面前现场调制，已经是值回票价。&quot;</span><br>doc = nlp(txt)<br><br>list1=[]<br><span class="hljs-keyword">for</span> token <span class="hljs-keyword">in</span> doc:<br>    <span class="hljs-keyword">if</span> token.is_stop == <span class="hljs-literal">False</span>: <span class="hljs-comment">#去除停用词</span><br>        list1.append(token)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">set</span>(list1))<br></code></pre></td></tr></table></figure><p>输出：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs python">&#123;浓郁, 苏苏, 甜, 人员, 小酌, 值回, 整盆, 起菜, 火箭, 伴吃, 牛, 漂亮, 道, 入口, 餐厅, 肉质, 披萨, 吃, 两, 现场, 朋友们, 口感, 菜, 银河, 搭配, 餐厅, 好吃, 入口, 升降机, 蜜瓜, 肠开, 时, 牛肉味, 榄油, 触手, 生长, 苏苏, 得宜, 意大利, 升降机, 苏苏, 口中, 流失, 满满, 香草, 好吃, 做, 面包, 家庭, 吸盘, 澳门, 甜蜜, 贵宾大堂, 形状, 超甜, 烹调, 交错, 浓, 烹调, 用橄, 满腔, 章鱼, 沿岸, 庭园, 黑毛, <span class="hljs-number">2</span>楼, 甘香, 大型, 得宜, 蕃茄, 松软, 黑醋, 吃, 章鱼, 吸盘, 餐饮, 氛围, 调味料, 来到, 大利, 味道, 果香, 肉质, 牛扒, 小酌, 服务员, 自家制, 面团, 苏苏忍, 精致, 喜欢, 口感, 轻松, 这天, 开胃, 战斧, 脂肪, 充满, 间, 苏苏, 餐厅, 回味, Q感, 一口气, 菜吃, 意大利, 菜带, 爱, 牛骨, 配意, 固定, 果碎, 部份, 问, 薄皮, 特别, 精髓, 苏苏, 相连, 里, 苏苏, 嚼劲, 芝麻, 面前, 意大利, 即切, 心中, 连骨, 火箭, 安战斧, 典雅, 牛肉, 欣赏, 开心, 专业, 吃, 感觉, 位于, 尝, 长长, 不错, 餐厅, 风格, 意大利, 厨艺, 肉肠, 披萨, 恰到好处, 真的, 面前, 火箭, 称为, 肋部, 踏出, 印弟, 肉, 充足, 披萨, 甜品, 苦, 欣赏, 我俩, 超爱, 章鱼, 烹调, 香味, 牛扒, 一道, 幸福感, 意大利, 经典, 现场, 平衡度, 吃, 好吃, 排, 软糯, 聚, 酱汁, 走廊, 意大利, 尽头, 咸甜, 芝士, 嫩滑, 苏Tiramisu, 滋味, 朋友, 意大利, 苏苏, 份, 酒店, 走进, 食材, 打卡, 吃, 缩水, 薄饼, 控制, 口感, 推介, 意大利, 吃掉, 吸盘, 章鱼, 朋友, 两, 朋友们, 聚一, 东翼, 到达, 爱, 配上, 熟成, 那种, 味道, 大厨, 口感, 餐厅, 拉米, 四溢, 件, 意大利, 排, 酒店, 火腿, 旁, 浓郁, 肉汁, 在内, 火喉, 好吃, 排, 餐时, 适合, 柠檬汁, 餐厅, 腿, 油香, 原能, 牛扒, 餐桌, 藏酒库, 份, 面包, 皮披萨, 香气, 两, 气氛, 两, 感觉, 香气, 聚会, 作, 骨髓, 毛猪, 骨肉, 味道, 软滑, 时, 杯, 美酒, 酒单, 面包, 香, 住口, 土豆, 猪火, 骨胶, 牛骨, 披萨皮, 兴趣, 手工, 脆脆, 菜吃, 文化, ....., 得名, 搭配, 牛, 美食, 开放式, 湿润, 配搭, 分享, 口水, 脆脆, 似, 橄榄油, 牛魔王, 牛扒, 装潢, 客人, 外, 好友, 沙律, 法国, 沙律, 芝士, 战斧, 流, 肉扒, 点独, 吃, 漂亮, 中, 错过, 厨们, 芝士, 次, 未, 票价, 菜(, 服务员, 口感, 新鲜, 时, 骨头, 走到, 空间感, 用餐, 好吃, 提拉米苏, 吃, 新鲜, 调制, 沙律, 菜), 制作, 土豆, 滋味, 华丽, 心果, 厨房&#125;<br></code></pre></td></tr></table></figure><blockquote><p>emmmmmm，感觉上分词效果一般……中文停用词不是每个都被消除了，最终结果中还存在不少无意义的单一文字，且部分名词被划分开（如：“战斧牛排”被拆分为“战斧”+“牛排”）</p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>学习</tag>
      
      <tag>NLP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>多项式特征的二分类次数确定问题</title>
    <link href="/2023/01/06/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%89%B9%E5%BE%81%E7%9A%84%E4%BA%8C%E5%88%86%E7%B1%BB%E6%AC%A1%E6%95%B0%E7%A1%AE%E5%AE%9A%E9%97%AE%E9%A2%98/"/>
    <url>/2023/01/06/%E5%A4%9A%E9%A1%B9%E5%BC%8F%E7%89%B9%E5%BE%81%E7%9A%84%E4%BA%8C%E5%88%86%E7%B1%BB%E6%AC%A1%E6%95%B0%E7%A1%AE%E5%AE%9A%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<blockquote><p><strong>问题描述：</strong><br>已知六个特征（记作$X_1,X_2…X_6$），取值为（-2,2），均值接近0（约-0.01），方差接近1（约1.15），设有函数$Y=a_0+a_1X^{b_1}_1+a_2X_2^{b_2}+…+a_6X_6^{b_6}$（假设最高项次数小于10），对Y做Sigmoid(Y)函数处理，输出为0/1（二分类），现有1000个样本（Train.txt：900作为训练集，100作为测试集），求矩阵a和b<br>限制：不使用神经网络和深度学习，主要支撑库为numpy</p></blockquote><p>$Sigmoid(Z)=\frac{1}{1+e^{-Z}}$</p><blockquote><p>实际结果：指数依次为0 4 2 3 1 5 6(第一个0为代表第一位为常量，用做偏移)<br>在已知次数的情况下，笔者梯度下降准确率为98.99%（全局），100%（测试集）<br>所用权重为：</p></blockquote><figure class="highlight plaintext"><figcaption><span>Text</span></figcaption><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs Plain">a0=-1.414120707795622245e+01,b0=0<br>a1=9.836514438332992771e-01,b1=4<br>a2=2.380517972559514028e+00,b2=2<br>a3=7.800843335621133745e-01,b3=3<br>a4=-7.085426102987223196e+00,b4=1<br>a5=-1.099617181010096756e+00,b5=5<br>a6=3.408382709960854906e-01,b6=6<br></code></pre></td></tr></table></figure><hr><hr><blockquote><p><strong>初步想法和思路：</strong></p></blockquote><ul><li><p>思路一：暴力循环</p><ul><li><p>遍历次数所有可能，对每一可能下进行机器学习梯度下降确定系数</p></li><li><p>问题：</p><ul><li>复杂度过高：共计$10^6$种可能组合（可以做优化，但指数级别复杂度不变），对每一种可能做机器学习不现实（单次耗时约10s）</li></ul></li></ul></li><li><p>思路二：最简单，也是暂时唯一验证的可行方式：试！</p><ul><li><p>每一项拆开，即设Ni为Xi的指数，从1~10进行遍历，保持其他项不变（形如：$Y=a_0+a_1X^{n}_1+1<em>X_2+…+1</em>X_6$，或将系数设置为0等）,理应在符合目标时拥有最高的准确率。重复六次，完成对指数的确定后，再进行梯度下降对系数进行学习。这种方式最多只需要60次确定指数。</p></li><li><p>问题</p><ul><li><p>一：如果不存在最高项次数小于10这一条件，我们无从谈起</p></li><li><p>二：实际上，对于形如这样的多项式Z = X+Y+T，排除Y和T，仅仅依靠离散点（如果连续或拥有无穷多样本点可行），我们无法证明Z和X之间满足什么关系（只看这两个变量很可能求出来没有相关性，如本题），即这种思路在数学逻辑上不完备，本题适用，可能在别的场景下不适用</p></li></ul></li><li><p>此外：</p><ul><li>此题适用，但必须说明，我们最终试验得到的最优取值，往往不止一个，我们会发现在某些特征的测试下，准确率非常接近，考虑到机器学习的误差，我们不能依靠细微的差距判断真正的次数，最终还需要再做判断</li></ul></li></ul></li><li><p>思路三：直接对全体进行梯度下降，学习a和b两个未知量</p><ul><li><p>问题：</p><ul><li><p>一：两者梯度交织，互相制约，互为约束条件</p></li><li><p>二：X取值含负数，这段无法求导，即没有梯度</p><ul><li>可以通过数据处理，全部映射为正数，但这会丢失一个重要数据：次数的奇偶性（Sigmoid函数看重正负而非绝对数值）</li></ul></li></ul></li></ul></li><li><p>思路四：指定系数，对指数梯度下降求解</p><ul><li><p>指定系数（如全为1），对$Y=a_0+X^{b_1}_1+X_2^{b_2}+…+X_6^{b_6}$这个函数进行梯度下降。大概率在指数与函数相同时准确率最高（我们认为指数比系数对结果影响更大）。</p></li><li><p>问题：</p><ul><li><p>一：X取值含负数，这段无法求导，更没有梯度一说</p><ul><li><p>可以通过数据处理，全部映射为正数，但这会丢失一个重要数据：次数的奇偶性（Sigmoid函数看重正负而非绝对数值）</p></li><li><p>实际测试结果结果相差过大，与实际几乎无关系</p></li></ul></li><li><p>二：系数怎么指定？</p><ul><li>全为1一定不会有好结果，如上所述，这会忽略特征的正负性，这对Sigmoid非常重要</li></ul></li></ul></li><li><p>分析：</p><blockquote><p>这种方法几乎一定有问题，不考虑学习率、次数为整数等细节，单从逻辑三段论上说，我们的假设“指数比系数对结果影响更大”这一条本身就有问题，我们的特征取值本身较小（-2,2），而实际上系数存在14以上的数值，在很多情况下“指数不比系数对结果影响大”</p></blockquote></li></ul></li><li><p>思路五：对三和四的结合优化</p><ul><li><p>先分析单一特征，得到正负相关性，在正负相关性的作用下进行如三的处理</p></li><li><p>问题：</p><ul><li>对于形如这样的多项式Z =X+Y+T，排除或固定Y和T，我们很可能发现证明Z和X之间满足什么关系，在Pearson相关性分析中，我们会发现他们不含有相关性（笔者认为主要原因是最终输出为0/1的离散点，对每一个特征每一个次方值测试全部“不相关”）</li></ul></li></ul></li></ul><blockquote><p><strong>分析：</strong></p></blockquote><ul><li><p>笔者认为，在判断次数这一问题上，主要难点在于我们使用的不是原始数据，而是经过了Sigmoid函数处理后的参数，Sigmoid函数将连续数据变为离散，这一步损失太大，也就直接导致了函数空间过大，相关性分析表示无相关性，否则我们完全可以直接最小二乘法拟合曲线……</p></li><li><p>可以尝试的想法：</p><ul><li><p>使用元学习单独对指数部分进行处理，因为已知为多项式函数，完全可以仿照现有模型自行仿造相似模型对元学习进行训练（不过如果采用这种方式，不如直接神经网络或深度学习让他直接输出0/1的结果……）</p></li><li><p>补充上述想法：有意义，他使得模型具有可解释性</p></li></ul></li></ul><hr><blockquote><p>后记：<br>本来以为是一个很简单的问题，没想到这么棘手，这几天推了好几遍公式，也尝试不同的数据处理和激活函数，但都不能解决本质问题……甚至还想过能不能将0/1倒推回离散的值（反正是可行解之一），也查了很多资料和文献，都没有发现想要的……现在做基础研究的成果比大热方向少太多了……之后会多看看数学方向，是否有更好的处理方法，在此留作记录</p></blockquote>]]></content>
    
    
    
    <tags>
      
      <tag>学习</tag>
      
      <tag>未解决</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>SVM下条件极值计算无解情况探究</title>
    <link href="/2023/01/06/SVM%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%9E%81%E5%80%BC%E8%AE%A1%E7%AE%97%E6%97%A0%E8%A7%A3%E6%83%85%E5%86%B5%E6%8E%A2%E7%A9%B6/"/>
    <url>/2023/01/06/SVM%E4%B8%8B%E6%9D%A1%E4%BB%B6%E6%9E%81%E5%80%BC%E8%AE%A1%E7%AE%97%E6%97%A0%E8%A7%A3%E6%83%85%E5%86%B5%E6%8E%A2%E7%A9%B6/</url>
    
    <content type="html"><![CDATA[<blockquote><p>SVM下条件极值计算，二维坐标系下，偏导结果为两条平行直线致无解情况，原因探究</p></blockquote><h1 id="三点情况"><a href="#三点情况" class="headerlink" title="三点情况"></a>三点情况</h1><ul><li>结果：当且仅当三点共线时无解</li></ul><hr><ul><li><p>证明：</p><ul><li><p>设存在三点$(x_1,y_1),(x_2,y_2),(x_3,y_3)$，分别为positive，positive，negative，即有$\lambda_1=1,\lambda_2=1,\lambda_3=-1$ 和 $y_1+y_2=y_3$</p><p>$ \begin{equation}<br>\begin{split}<br>\mathcal{J}(\boldsymbol{\lambda})<br> &amp;=\frac{1}{2} \sum_{i=1}^N \sum_{j=1}^N \lambda_i \lambda_j y^{(i)} y^{(j)}\left(\boldsymbol{x}^{(i)}\right)^T \boldsymbol{x}^{(j)}-\sum_{i=1}^N \lambda_i\\<br>&amp;=1/2[(x_1^2+y_1^2) \lambda_1^2+(x_1x_2+y_1y_2)\lambda_1\lambda_2-(x_1x_3+y_1y_3)\lambda_1\lambda_3\\<br>&amp;\ \ +(x_2^2+y_2^2) \lambda_2^2+(x_1x_2+y_1y_2)\lambda_1\lambda_2-(x_2x_3+y_2y_3)\lambda_2\lambda_3\\<br>&amp;\ \ +(x_3^2+y_3^2) \lambda_3^2-(x_2x_3+y_2y_3)\lambda_2\lambda_3-(x_2x_3+y_2y_3)\lambda_1\lambda_3]\\<br>&amp;\ \ -\lambda_1-\lambda_2-\lambda_3\\<br>&amp;=1/2[(x_1^2+y_1^2) \lambda_1^2+(x_2^2+y_2^2) \lambda_2^2+(x_3^2+y_3^2) \lambda_3^2\\<br>&amp;\ \ +2(x_1x_2+y_1y_2)\lambda_1\lambda_2<br>+2(x_1x_3+y_1y_3)\lambda_1\lambda_3<br>-2(x_2x_3+y_2y_3)\lambda_2\lambda_3]\\<br>&amp;\ \ -\lambda_1-\lambda_2-\lambda_3\\<br>\end{split}<br>\end{equation} $</p><p>由 $y_1+y_2=y_3$，将$y_3$带入消去：</p><p>$\begin{equation}<br>\begin{split}<br>\mathcal{J}(\boldsymbol{\lambda})=&amp;1/2[(x_1^2+y_1^2+x_3^2+y_3^2-2x_1x_3-2y_1y_3)\lambda_1^2\\<br>&amp;+(x_2^2+y_2^2+x_3^2+y_3^2-2x_2x_3-2y_2y_3)\lambda_2^2\\<br>&amp;+2(x_3^2+y_3^2+x_1x_2+y_1y_2-x_1x_3-y_1y_3-x_2x_3-y_2y_3)\lambda_1\lambda_2]\\<br>&amp; -2\lambda_1-2\lambda_2\\<br>=&amp;1/2[((x_1-x_3)^2+(y_1-y_3)^2)\lambda_1^2\\<br>&amp;+((x_2-x_3)^2+(y_2-y_3)^2))\lambda_2^2\\<br>&amp;+2((x_3-x1)(x_3-x_2)+(y_3-y_1)(y_3-y_2))\lambda_1\lambda_2]\\<br>&amp; -2\lambda_1-2\lambda_2\\<br>\end{split}<br>\end{equation}$</p><p>对此分别对$\lambda_1，\lambda_2$求偏导</p><script type="math/tex; mode=display">\begin{equation}\begin{split}\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_1} =& ((x_1-x_3)^2+(y_1-y_3)^2)\lambda_1\\+&[(x_3-x_1)(x_3-x_2)+(y_3-y_1)(y_3-y_2)]\lambda_2 -2\end{split}\end{equation}</script><p>$\begin{equation}<br>\begin{split}<br>\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_2} =&amp; ((x_2-x_3)^2+(y_2-y_3)^2)\lambda_1\+&amp;[(x_3-x_1)(x_3-x_2)+(y_3-y_1)(y_3-y_2)]\lambda_1 -2<br>\end{split}<br>\end{equation}$</p><p>令式(3)(4)为0，可求出其条件极值，显然，当两式平行时无解。故令式(3)(4)为0，且斜率相等，联立求解可得：</p><p>$\begin{equation}<br>\begin{split}<br>\frac{y_3-y_1}{x_3-x_1}=\frac{y_3-y_2}{x_3-x_2}<br>\end{split}<br>\end{equation}$</p><p>上式表示过点1,3直线的斜率与过点2,3的直线的斜率相等，<strong>显然其三点共线</strong></p></li></ul></li><li><p>验证：</p><ul><li>以点(1,1)(2,2)(3,3)为例（三点共线），分别为positive，positive，negative</li></ul><p>$\begin{equation}<br>\begin{split}<br>\mathcal{J}(\boldsymbol{\lambda})=4\lambda_1^2+\lambda_2^2+4\lambda_1\lambda_2-2\lambda_1-2\lambda_2<br>\end{split}<br>\end{equation}$</p><p>$\begin{equation}<br>\begin{split}<br>\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_1} =8\lambda_1+4\lambda_2-2<br>\end{split}<br>\end{equation}$</p><p>$\begin{equation}<br>\begin{split}<br>\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_2} =4\lambda_1+2\lambda_2-2<br>\end{split}<br>\end{equation}$</p><p>两式平行，无解</p></li></ul><h1 id="四点情况"><a href="#四点情况" class="headerlink" title="四点情况"></a>四点情况</h1><ul><li><p>结果：一定无解</p></li><li><p>证明：</p><ul><li>设存在三点$(x_1,y_1),(x_2,y_2),(x_3,y_3),(x_4,y_4)$，分别为positive，positive，negative，negative，即有$\lambda_1=1,\lambda_2=1,\lambda_3=-1,\lambda_4=-1$ 和 $y_1+y_2=y_3+y_4$（计算方式同上，具体计算细节见附录）</li><li>为计算简洁，另$X_{ij}=x_i-x_j,Y_{ij}=y_i-y_j$，这里消去$\lambda_4$</li><li>分别对$\lambda_1，\lambda_2，\lambda_3$求偏导</li></ul><p>$\begin{equation}<br>\begin{split}<br>\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_1} =&amp; (X_{14}^2+Y_{14}^2)\lambda_1+(X_{14}X_{24}+Y_{14}Y_{24})\lambda_2-(X_{14}X_{34}+Y_{14}Y_{34})\lambda_3-2<br>\end{split}<br>\end{equation}$</p><p>$\begin{equation}<br>\begin{split}<br>\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_2} =&amp; (X_{24}^2+Y_{24}^2)\lambda_2+(X_{14}X_{24}+Y_{14}Y_{24})\lambda_1-(X_{24}X_{34}+Y_{24}Y_{34})\lambda_3-2<br>\end{split}<br>\end{equation}$</p><p>$\begin{equation}<br>\begin{split}<br>\frac{\partial \mathcal{J}(\lambda) }{ \partial \lambda_3} =&amp; (X_{34}^2+Y_{34}^2)\lambda_3-(X_{14}X_{34}+Y_{14}Y_{34})\lambda_1-(X_{24}X_{34}+Y_{24}Y_{34})\lambda_2-2<br>\end{split}<br>\end{equation}$</p><p>使用系数行列式：</p><p>$\left |\begin{array}{cccc}<br>X_{14}^2+Y_{14}^2 &amp;X_{14}X_{24}+Y_{14}Y_{24}   &amp; -(X_{14}X_{34}+Y_{14}Y_{34}) \\<br>X_{14}X_{24}+Y_{14}Y_{24} &amp;X_{24}^2+Y_{24}^2 &amp; -(X_{14}X_{34}+Y_{14}Y_{34})  \\<br>-(X_{14}X_{34}+Y_{14}Y_{34}) &amp; -(X_{24}X_{34}+Y_{24}Y_{34}) &amp;X_{34}^2+Y_{34}^2 \\<br>\end{array}\right|$</p><p>上式计算后结果为0，即函数无解（具体计算方式为，第二三行分别减去第一行的倍数消去$\lambda_1$,得到仅含$\lambda_2，\lambda_3$的两个计算式，这两式平行，斜率如下，计算细节见附录）</p><p>$\begin{equation}<br>\begin{split}<br>\frac{X_{14}Y_{24}-X_{24}Y_{14}}{X_{14}Y_{14}-X_{14}Y_{34}}<br>\end{split}<br>\end{equation}$</p><blockquote><p>综上所述，其一定求出结果为无解</p></blockquote></li></ul><h1 id="附录"><a href="#附录" class="headerlink" title="附录"></a>附录</h1><p><img src="https://picture-for-mark.oss-cn-hangzhou.aliyuncs.com/img/IMG_20221102_220253.jpg" alt="IMG_20221102_220253"></p><blockquote><p>上式计算并消去$\lambda_4$进行求导</p></blockquote><p><img src="https://picture-for-mark.oss-cn-hangzhou.aliyuncs.com/img/IMG_20221102_220348.jpg" alt="IMG_20221102_220348"></p><blockquote><p>上式计算一个式子的斜率，另一边方法相同</p></blockquote><hr><blockquote><p>关于“无解”的数学解释：</p></blockquote><ul><li><p>在限定条件取值范围内不存在极值点，从二维坐标系来看指函数单调，即仅存在边界处的最值点</p></li><li><p>从直觉上感觉，所使用的点越多，$\lambda$之间交织的限制越严格，越难以得到可行解，如使用两个点一定有解，三点仅在共线时无解，四点始终无解（猜测5及以后也无解……~）</p></li></ul>]]></content>
    
    
    
    <tags>
      
      <tag>学习</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
